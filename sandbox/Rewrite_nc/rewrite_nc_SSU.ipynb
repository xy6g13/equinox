{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import dask\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mitequinox.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import PBSCluster\n",
    "local_dir = os.getenv('TMPDIR')\n",
    "cluster = PBSCluster(local_directory=local_dir)\n",
    "#print(cluster.job_script())\n",
    "w = cluster.start_workers(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dask handles and check dask server status\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.148.1.13:54710\n",
       "  <li><b>Dashboard: </b><a href='http://10.148.1.13:8787/status' target='_blank'>http://10.148.1.13:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>24</li>\n",
       "  <li><b>Cores: </b>96</li>\n",
       "  <li><b>Memory: </b>1200.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.148.1.13:54710' processes=14 cores=56>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# automatic rewriting of all variables (for spectral calculations)\n",
    "\n",
    "# transposed data: (i,j,time), 1 file per face, time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "face_60 = [1, 2, 4, 5, 7, 8, 10, 11]\n",
    "face_60 = [5]\n",
    "\n",
    "print(face_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:735: UserWarning: Couldn't find available_diagnostics.log in . Using default version.\n",
      "  \"in %s. Using default version.\" % data_dir)\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/utils.py:336: UserWarning: Not sure what to do with rlev = L\n",
      "  warnings.warn(\"Not sure what to do with rlev = \" + rlev)\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:249: FutureWarning: iteration over an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Iterate over the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  for vname in ds:\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/utils.py:1010: UserWarning: Deprecated, see dask.base.get_scheduler instead\n",
      "  warnings.warn(\"Deprecated, see dask.base.get_scheduler instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 38s, sys: 5.77 s, total: 1min 44s\n",
      "Wall time: 5min 41s\n",
      "face=5 / i=0\n"
     ]
    }
   ],
   "source": [
    "V = ['SSU']\n",
    "\n",
    "transpose = True # False untested\n",
    "\n",
    "if transpose:\n",
    "    Nt = 24*10*3 # time windows to consider\n",
    "    out_dir = scratch+'/mit_nc_t/'\n",
    "    #out_dir = 'home1/datawork/xyu/'\n",
    "    fsize_bound = 15*1e9*3\n",
    "else:\n",
    "    Nt = 1\n",
    "    out_dir = scratch+'/mit_nc/'    \n",
    "    fsize_bound = 60*1e6    \n",
    "\n",
    "for v in V:\n",
    "    #\n",
    "    data_dir = root_data_dir+v+'/'\n",
    "    iters, time = get_iters_time(v, data_dir, delta_t=25.)\n",
    "    #\n",
    "    #it = np.arange(time.size/Nt-1).astype(int)*Nt\n",
    "    it = np.arange(1).astype(int)*Nt # tmp\n",
    "    assert it[-1]+Nt<time.size\n",
    "    #\n",
    "    p = 'C'\n",
    "    vdrop = ['XC','YC','Depth','rA']\n",
    "    if v is 'SSU':\n",
    "        p = 'W'\n",
    "        vdrop = ['dxC','dyG','Depth','rAw']        \n",
    "    elif v is 'SSV':\n",
    "        p = 'S'\n",
    "        vdrop = ['dxG','dyC','rAs']       \n",
    "    #\n",
    "    ds = get_compressed_data(v, data_dir, grid_dir, iters=iters, time=time, client=client, point=p)\n",
    "    #ds = ds.chunk({'face': 1})\n",
    "    #\n",
    "    #for face in range(ds['face'].size):\n",
    "    for face in face_60:   \n",
    "        for i, t in enumerate(it):\n",
    "            #\n",
    "            file_out = out_dir+'/%s_f%02d_t%02d.nc'%(v,face,i)\n",
    "            if not os.path.isfile(file_out) or os.path.getsize(file_out) < fsize_bound:            \n",
    "                dv = ds[v].isel(time=slice(t,t+Nt), face=face) \n",
    "                # should store grid data independantly in a single file\n",
    "                #dv = dv.drop(['XC','YC','Depth','rA']).to_dataset()\n",
    "                dv = dv.drop(['dyG','dxC','rAw']).to_dataset()\n",
    "\n",
    "                #\n",
    "                if transpose:\n",
    "                    dv = dv.chunk({'time': dv['time'].size, 'i_g': 432, 'j': 432})\n",
    "                    dv = dv.transpose('i_g','j','time')\n",
    "                    chunksizes = [432, 432, dv['time'].size]\n",
    "                else:\n",
    "                    dv = dv.chunk({'i': 432, 'j': 432})\n",
    "                    chunksizes = [1, 432, 432]\n",
    "                #print(dv)\n",
    "                #\n",
    "                while True:\n",
    "                    try:\n",
    "                        %time dv.to_netcdf(file_out, mode='w', unlimited_dims=['time'], \\\n",
    "                                           encoding={'SSU': {'chunksizes': chunksizes}})\n",
    "                    except:\n",
    "                        print('Failure')\n",
    "                    if os.path.isfile(file_out) and os.path.getsize(file_out)>fsize_bound:\n",
    "                        #\n",
    "                        print('face=%d / i=%d'%(face,i))\n",
    "                        break\n",
    "            else:\n",
    "                print('face=%d / i=%d - allready processed'%(face,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# standard data layout: (face, j, i), 1 file per time (for movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home1/scratch/xyu/mit_nc_t/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:735: UserWarning: Couldn't find available_diagnostics.log in . Using default version.\n",
      "  \"in %s. Using default version.\" % data_dir)\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/utils.py:336: UserWarning: Not sure what to do with rlev = L\n",
      "  warnings.warn(\"Not sure what to do with rlev = \" + rlev)\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:249: FutureWarning: iteration over an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Iterate over the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  for vname in ds:\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/utils.py:1010: UserWarning: Deprecated, see dask.base.get_scheduler instead\n",
      "  warnings.warn(\"Deprecated, see dask.base.get_scheduler instead\")\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/worker.py:820: UserWarning: Large object of size 3.82 MB detected in task graph: \n",
      "  (\"('astype-abef5b315fef5b10b499827f5e3f68da', 0, 0 ... f62b>]), False)\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  % (format_bytes(len(b)), s))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 80 ms, total: 1.3 s\n",
      "Wall time: 10.4 s\n",
      "i=0, iter=228096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/utils.py:1010: UserWarning: Deprecated, see dask.base.get_scheduler instead\n",
      "  warnings.warn(\"Deprecated, see dask.base.get_scheduler instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 724 ms, sys: 64 ms, total: 788 ms\n",
      "Wall time: 4.65 s\n",
      "i=1, iter=228240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/utils.py:1010: UserWarning: Deprecated, see dask.base.get_scheduler instead\n",
      "  warnings.warn(\"Deprecated, see dask.base.get_scheduler instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 732 ms, sys: 40 ms, total: 772 ms\n",
      "Wall time: 4.75 s\n",
      "i=2, iter=228384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/utils.py:1010: UserWarning: Deprecated, see dask.base.get_scheduler instead\n",
      "  warnings.warn(\"Deprecated, see dask.base.get_scheduler instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 732 ms, sys: 44 ms, total: 776 ms\n",
      "Wall time: 4.73 s\n",
      "i=3, iter=228528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/utils.py:1010: UserWarning: Deprecated, see dask.base.get_scheduler instead\n",
      "  warnings.warn(\"Deprecated, see dask.base.get_scheduler instead\")\n"
     ]
    }
   ],
   "source": [
    "V = ['Eta', 'SST', 'SSS', 'SSU', 'SSV']\n",
    "V = ['SSU']\n",
    "\n",
    "Nt = 1\n",
    "out_dir = '/home1/work/xyu/LLC4320/'  \n",
    "print(out_dir)\n",
    "\n",
    "fsize_bound = 13*60*1e6\n",
    "\n",
    "for v in V:\n",
    "    #\n",
    "    data_dir = root_data_dir+v+'/'\n",
    "    iters, time = get_iters_time(v, data_dir, delta_t=25.)\n",
    "    #\n",
    "    it = np.arange(time.size/Nt-1).astype(int)*Nt\n",
    "    it = np.arange(3).astype(int)*Nt # tmp\n",
    "    assert it[-1]+Nt<time.size\n",
    "    #\n",
    "    p = 'C'\n",
    "    vdrop = ['XC','YC','Depth','rA']\n",
    "    if v is 'SSU':\n",
    "        p = 'W'\n",
    "        vdrop = ['dxC','dyG','rAw']        \n",
    "    elif v is 'SSV':\n",
    "        p = 'S'\n",
    "        vdrop = ['dxG','dyC','rAs']        \n",
    "    #\n",
    "    ds = get_compressed_data(v, data_dir, grid_dir, iters=iters, time=time, client=client, point=p)\n",
    "    \n",
    "    #ds = ds.chunk({'face': 1})\n",
    "    #\n",
    "    for i, t in enumerate(it):\n",
    "        #\n",
    "        file_out = out_dir+'/%s_t%04d.nc'%(v,i)\n",
    "        if not os.path.isfile(file_out) or os.path.getsize(file_out) < fsize_bound:            \n",
    "            dv = ds[v].isel(time=slice(t,t+Nt)) \n",
    "            # should store grid data independantly in a single file\n",
    "            dv = dv.drop(vdrop).to_dataset()\n",
    "            #\n",
    "            #print(dv)\n",
    "            #\n",
    "            while True:\n",
    "                try:\n",
    "                    #print(dv)\n",
    "                    %time dv.to_netcdf(file_out, mode='w')                    \n",
    "                except:\n",
    "                    print('Failure')\n",
    "                if os.path.isfile(file_out) and os.path.getsize(file_out) > fsize_bound:\n",
    "                    #\n",
    "                    print('i=%d, iter=%d'%(i, iters[i].values))\n",
    "                    break\n",
    "        else:\n",
    "            print('i=%d, iter=%d - allready processed'%(i, iters[i].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future finished result=None>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.scheduler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
