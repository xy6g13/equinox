{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/cmocean/tools.py:76: MatplotlibDeprecationWarning: The is_string_like function was deprecated in version 2.1.\n",
      "  if not mpl.cbook.is_string_like(rgbin[0]):\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import dask\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mitequinox.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/utils.py:128: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable\n",
      "  % (host, default, e), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "dmethod = 1\n",
    "#\n",
    "if dmethod == 0:\n",
    "    client = None\n",
    "if dmethod == 1:\n",
    "    from dask.distributed import Client\n",
    "    scheduler = os.getenv('DATAWORK')+'/dask/scheduler.json'\n",
    "    client = Client(scheduler_file=scheduler)\n",
    "elif dmethod == 2:\n",
    "    from dask_jobqueue import PBSCluster\n",
    "    # folder where data is spilled when RAM is filled up\n",
    "    local_dir = os.getenv('TMPDIR')\n",
    "    #\n",
    "    cluster = PBSCluster(queue='mpi_1', local_directory=local_dir, interface='ib0', walltime='24:00:00',\n",
    "                         threads=14, processes=2, memory='50GB', resource_spec='select=1:ncpus=28:mem=100g', \n",
    "                         death_timeout=100)\n",
    "    w = cluster.start_workers(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to wait for workers to spin up\n",
    "if dmethod == 2:\n",
    "    cluster.scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dask handles and check dask server status\n",
    "if dmethod == 2:\n",
    "    from dask.distributed import Client\n",
    "    client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.148.0.40:8786\n",
       "  <li><b>Dashboard: </b><a href='http://10.148.0.40:8787/status' target='_blank'>http://10.148.0.40:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>20</li>\n",
       "  <li><b>Cores: </b>280</li>\n",
       "  <li><b>Memory: </b>2000.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.148.0.40:8786' processes=20 cores=280>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# store grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:721: UserWarning: Couldn't find available_diagnostics.log in . Using default version.\n",
      "  \"in %s. Using default version.\" % data_dir)\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/utils.py:314: UserWarning: Not sure what to do with rlev = L\n",
      "  warnings.warn(\"Not sure what to do with rlev = \" + rlev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (face: 13, i: 4320, i_g: 4320, j: 4320, j_g: 4320, k: 90, k_l: 90, k_p1: 91, k_u: 90)\n",
      "Coordinates:\n",
      "  * i        (i) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * i_g      (i_g) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * j        (j) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * j_g      (j_g) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * k        (k) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * k_u      (k_u) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * k_l      (k_l) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * k_p1     (k_p1) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * face     (face) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
      "    XC       (face, j, i) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    YC       (face, j, i) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    XG       (face, j_g, i_g) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    YG       (face, j_g, i_g) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    rA       (face, j, i) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    Depth    (face, j, i) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "Data variables:\n",
      "    *empty*\n",
      "Attributes:\n",
      "    Conventions:  CF-1.6\n",
      "    title:        netCDF wrapper of MITgcm MDS binary data\n",
      "    source:       MITgcm\n",
      "    history:      Created by calling `open_mdsdataset(llc_method='smallchunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:235: FutureWarning: iteration over an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Iterate over the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  for vname in ds:\n"
     ]
    }
   ],
   "source": [
    "ds_index, ds = get_compressed_level_index(grid_dir)\n",
    "\n",
    "ds = ds.drop(['dxG','dyG','dxC','dyC','rAw','rAs','rAz'])\n",
    "ds = ds.drop(['hFacC','hFacW','hFacS'])\n",
    "ds = ds.drop(['Z', 'Zp1', 'Zu', 'Zl', 'drC', 'drF','PHrefC','PHrefF'])\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home1/scratch/xyu/\n"
     ]
    }
   ],
   "source": [
    "out_dir = scratch+'/'\n",
    "print(out_dir)\n",
    "\n",
    "file_out = out_dir+'mit_grid.nc'\n",
    "ds.to_netcdf(file_out, mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (face: 13, i: 4320, i_g: 4320, j: 4320, j_g: 4320, k: 90, k_l: 90, k_p1: 91, k_u: 90)\n",
      "Coordinates:\n",
      "  * i        (i) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * i_g      (i_g) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * j        (j) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * j_g      (j_g) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * k        (k) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * k_u      (k_u) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * k_l      (k_l) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * k_p1     (k_p1) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * face     (face) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
      "    XC       (face, i, j) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    YC       (face, i, j) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    XG       (face, i_g, j_g) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    YG       (face, i_g, j_g) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    rA       (face, i, j) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    Depth    (face, i, j) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "Data variables:\n",
      "    *empty*\n",
      "Attributes:\n",
      "    Conventions:  CF-1.6\n",
      "    title:        netCDF wrapper of MITgcm MDS binary data\n",
      "    source:       MITgcm\n",
      "    history:      Created by calling `open_mdsdataset(llc_method='smallchunks...\n"
     ]
    }
   ],
   "source": [
    "dst = ds.transpose('face', 'i', 'j', 'i_g', 'j_g', 'k', 'k_l', 'k_p1', 'k_u')\n",
    "print(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out = out_dir+'mit_grid_t.nc'\n",
    "dst.to_netcdf(file_out, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# automatic rewriting of all variables (for spectral calculations)\n",
    "\n",
    "# transposed data: (i,j,time), 1 file per face, time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:721: UserWarning: Couldn't find available_diagnostics.log in . Using default version.\n",
      "  \"in %s. Using default version.\" % data_dir)\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/utils.py:314: UserWarning: Not sure what to do with rlev = L\n",
      "  warnings.warn(\"Not sure what to do with rlev = \" + rlev)\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:235: FutureWarning: iteration over an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Iterate over the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  for vname in ds:\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/worker.py:742: UserWarning: Large object of size 3.14 MB detected in task graph: \n",
      "  (\"('astype-e8312cbadd56f5ef6d10c13e01be9cde', 0, 0 ... b887>]), False)\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  % (format_bytes(len(b)), s))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.2 s, sys: 260 ms, total: 33.5 s\n",
      "Wall time: 2min 19s\n",
      "face=11 / i=0\n",
      "CPU times: user 33.9 s, sys: 232 ms, total: 34.2 s\n",
      "Wall time: 2min 7s\n",
      "face=11 / i=1\n",
      "CPU times: user 33.3 s, sys: 276 ms, total: 33.6 s\n",
      "Wall time: 2min 21s\n",
      "face=11 / i=2\n",
      "CPU times: user 33.4 s, sys: 280 ms, total: 33.7 s\n",
      "Wall time: 2min 13s\n",
      "face=11 / i=3\n",
      "CPU times: user 33.2 s, sys: 256 ms, total: 33.4 s\n",
      "Wall time: 2min 8s\n",
      "face=11 / i=4\n",
      "CPU times: user 33.4 s, sys: 256 ms, total: 33.6 s\n",
      "Wall time: 2min 11s\n",
      "face=12 / i=0\n",
      "CPU times: user 33.1 s, sys: 320 ms, total: 33.5 s\n",
      "Wall time: 2min 15s\n",
      "face=12 / i=1\n",
      "CPU times: user 33.5 s, sys: 248 ms, total: 33.7 s\n",
      "Wall time: 2min 12s\n",
      "face=12 / i=2\n",
      "CPU times: user 33.3 s, sys: 296 ms, total: 33.6 s\n",
      "Wall time: 2min 9s\n",
      "face=12 / i=3\n",
      "CPU times: user 33.8 s, sys: 248 ms, total: 34 s\n",
      "Wall time: 2min 15s\n",
      "face=12 / i=4\n"
     ]
    }
   ],
   "source": [
    "V = ['Eta', 'SST', 'SSS', 'SSU', 'SSV']\n",
    "V = ['SSV']\n",
    "\n",
    "transpose = True # False untested\n",
    "\n",
    "if transpose:\n",
    "    Nt = 24*10 # time windows to consider\n",
    "    out_dir = scratch+'/mit_nc/'\n",
    "    fsize_bound = 15*1e9\n",
    "else:\n",
    "    Nt = 1\n",
    "    out_dir = scratch+'/mit_nc/'    \n",
    "    fsize_bound = 60*1e6    \n",
    "\n",
    "for v in V:\n",
    "    #\n",
    "    data_dir = root_data_dir+v+'/'\n",
    "    iters, time = get_iters_time(v, data_dir, delta_t=25.)\n",
    "    #\n",
    "    #it = np.arange(time.size/Nt-1).astype(int)*Nt\n",
    "    it = np.arange(5).astype(int)*Nt # tmp\n",
    "    assert it[-1]+Nt<time.size\n",
    "    #\n",
    "    p = 'C'\n",
    "    if v is 'SSU':\n",
    "        p = 'W'\n",
    "    elif v is 'SSV':\n",
    "        p = 'S'\n",
    "    #\n",
    "    ds = get_compressed_data(v, data_dir, grid_dir, iters=iters, time=time, client=client, point=p)\n",
    "    #ds = ds.chunk({'face': 1})\n",
    "    #\n",
    "    for face in range(11,13):\n",
    "        for i, t in enumerate(it):\n",
    "            #\n",
    "            file_out = out_dir+'/%s_f%02d_t%02d.nc'%(v,face,i)\n",
    "            if not os.path.isfile(file_out) or os.path.getsize(file_out) < fsize_bound:            \n",
    "                dv = ds[v].isel(time=slice(t,t+Nt), face=face) \n",
    "                # should store grid data independantly in a single file\n",
    "                dv = dv.drop(['XC','YC','Depth','rA']).to_dataset()\n",
    "                #\n",
    "                if transpose:\n",
    "                    dv = dv.chunk({'time': dv['time'].size, 'i': 432, 'j': 432})\n",
    "                    dv = dv.transpose('i','j','time')\n",
    "                    chunksizes = [432, 432, dv['time'].size]\n",
    "                else:\n",
    "                    dv = dv.chunk({'i': 432, 'j': 432})\n",
    "                    chunksizes = [1, 432, 432]\n",
    "                #print(dv)\n",
    "                #\n",
    "                while True:\n",
    "                    try:\n",
    "                        %time dv.to_netcdf(file_out, mode='w', unlimited_dims=['time'], \\\n",
    "                                           encoding={'SSV': {'chunksizes': chunksizes}})\n",
    "                    except:\n",
    "                        print('Failure')\n",
    "                    if os.path.isfile(file_out) and os.path.getsize(file_out)>fsize_bound:\n",
    "                        #\n",
    "                        print('face=%d / i=%d'%(face,i))\n",
    "                        break\n",
    "            else:\n",
    "                print('face=%d / i=%d - allready processed'%(face,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# standard data layout: (face, j, i), 1 file per time (for movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:721: UserWarning: Couldn't find available_diagnostics.log in . Using default version.\n",
      "  \"in %s. Using default version.\" % data_dir)\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/utils.py:314: UserWarning: Not sure what to do with rlev = L\n",
      "  warnings.warn(\"Not sure what to do with rlev = \" + rlev)\n",
      "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:235: FutureWarning: iteration over an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Iterate over the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  for vname in ds:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0, iter=228096 - allready processed\n",
      "i=1, iter=228240 - allready processed\n",
      "i=2, iter=228384 - allready processed\n",
      "i=3, iter=228528 - allready processed\n",
      "i=4, iter=228672 - allready processed\n",
      "i=5, iter=228816 - allready processed\n",
      "i=6, iter=228960 - allready processed\n",
      "i=7, iter=229104 - allready processed\n",
      "i=8, iter=229248 - allready processed\n",
      "i=9, iter=229392 - allready processed\n",
      "i=10, iter=229536 - allready processed\n",
      "i=11, iter=229680 - allready processed\n",
      "i=12, iter=229824 - allready processed\n",
      "i=13, iter=229968 - allready processed\n",
      "i=14, iter=230112 - allready processed\n",
      "i=15, iter=230256 - allready processed\n",
      "i=16, iter=230400 - allready processed\n",
      "i=17, iter=230544 - allready processed\n",
      "i=18, iter=230688 - allready processed\n",
      "i=19, iter=230832 - allready processed\n",
      "i=20, iter=230976 - allready processed\n",
      "i=21, iter=231120 - allready processed\n",
      "i=22, iter=231264 - allready processed\n",
      "i=23, iter=231408 - allready processed\n",
      "i=24, iter=231552 - allready processed\n",
      "i=25, iter=231696 - allready processed\n",
      "i=26, iter=231840 - allready processed\n",
      "i=27, iter=231984 - allready processed\n",
      "i=28, iter=232128 - allready processed\n",
      "i=29, iter=232272 - allready processed\n",
      "i=30, iter=232416 - allready processed\n",
      "i=31, iter=232560 - allready processed\n",
      "i=32, iter=232704 - allready processed\n",
      "i=33, iter=232848 - allready processed\n",
      "i=34, iter=232992 - allready processed\n",
      "i=35, iter=233136 - allready processed\n",
      "i=36, iter=233280 - allready processed\n",
      "i=37, iter=233424 - allready processed\n",
      "i=38, iter=233568 - allready processed\n",
      "i=39, iter=233712 - allready processed\n",
      "i=40, iter=233856 - allready processed\n",
      "i=41, iter=234000 - allready processed\n",
      "i=42, iter=234144 - allready processed\n",
      "i=43, iter=234288 - allready processed\n",
      "i=44, iter=234432 - allready processed\n",
      "i=45, iter=234576 - allready processed\n",
      "i=46, iter=234720 - allready processed\n",
      "i=47, iter=234864 - allready processed\n",
      "i=48, iter=235008 - allready processed\n",
      "i=49, iter=235152 - allready processed\n",
      "i=50, iter=235296 - allready processed\n",
      "i=51, iter=235440 - allready processed\n",
      "i=52, iter=235584 - allready processed\n",
      "i=53, iter=235728 - allready processed\n",
      "i=54, iter=235872 - allready processed\n",
      "i=55, iter=236016 - allready processed\n",
      "i=56, iter=236160 - allready processed\n",
      "i=57, iter=236304 - allready processed\n",
      "i=58, iter=236448 - allready processed\n",
      "i=59, iter=236592 - allready processed\n",
      "i=60, iter=236736 - allready processed\n",
      "i=61, iter=236880 - allready processed\n",
      "i=62, iter=237024 - allready processed\n",
      "i=63, iter=237168 - allready processed\n",
      "i=64, iter=237312 - allready processed\n",
      "i=65, iter=237456 - allready processed\n",
      "i=66, iter=237600 - allready processed\n",
      "i=67, iter=237744 - allready processed\n",
      "i=68, iter=237888 - allready processed\n",
      "i=69, iter=238032 - allready processed\n",
      "i=70, iter=238176 - allready processed\n",
      "i=71, iter=238320 - allready processed\n",
      "i=72, iter=238464 - allready processed\n",
      "i=73, iter=238608 - allready processed\n",
      "i=74, iter=238752 - allready processed\n",
      "i=75, iter=238896 - allready processed\n",
      "i=76, iter=239040 - allready processed\n",
      "i=77, iter=239184 - allready processed\n",
      "i=78, iter=239328 - allready processed\n",
      "i=79, iter=239472 - allready processed\n",
      "i=80, iter=239616 - allready processed\n",
      "i=81, iter=239760 - allready processed\n",
      "i=82, iter=239904 - allready processed\n",
      "i=83, iter=240048 - allready processed\n",
      "i=84, iter=240192 - allready processed\n",
      "i=85, iter=240336 - allready processed\n",
      "i=86, iter=240480 - allready processed\n",
      "i=87, iter=240624 - allready processed\n",
      "i=88, iter=240768 - allready processed\n",
      "i=89, iter=240912 - allready processed\n",
      "i=90, iter=241056 - allready processed\n",
      "i=91, iter=241200 - allready processed\n",
      "i=92, iter=241344 - allready processed\n",
      "i=93, iter=241488 - allready processed\n",
      "i=94, iter=241632 - allready processed\n",
      "i=95, iter=241776 - allready processed\n",
      "i=96, iter=241920 - allready processed\n",
      "i=97, iter=242064 - allready processed\n",
      "i=98, iter=242208 - allready processed\n",
      "i=99, iter=242352 - allready processed\n",
      "i=100, iter=242496 - allready processed\n",
      "i=101, iter=242640 - allready processed\n",
      "i=102, iter=242784 - allready processed\n",
      "i=103, iter=242928 - allready processed\n",
      "i=104, iter=243072 - allready processed\n",
      "i=105, iter=243216 - allready processed\n",
      "i=106, iter=243360 - allready processed\n",
      "i=107, iter=243504 - allready processed\n",
      "i=108, iter=243648 - allready processed\n",
      "i=109, iter=243792 - allready processed\n",
      "i=110, iter=243936 - allready processed\n",
      "i=111, iter=244080 - allready processed\n",
      "i=112, iter=244224 - allready processed\n",
      "i=113, iter=244368 - allready processed\n",
      "i=114, iter=244512 - allready processed\n",
      "i=115, iter=244656 - allready processed\n",
      "i=116, iter=244800 - allready processed\n",
      "i=117, iter=244944 - allready processed\n",
      "i=118, iter=245088 - allready processed\n",
      "i=119, iter=245232 - allready processed\n",
      "i=120, iter=245376 - allready processed\n",
      "i=121, iter=245520 - allready processed\n",
      "i=122, iter=245664 - allready processed\n",
      "i=123, iter=245808 - allready processed\n",
      "i=124, iter=245952 - allready processed\n",
      "i=125, iter=246096 - allready processed\n",
      "i=126, iter=246240 - allready processed\n",
      "i=127, iter=246384 - allready processed\n",
      "i=128, iter=246528 - allready processed\n",
      "i=129, iter=246672 - allready processed\n",
      "i=130, iter=246816 - allready processed\n",
      "i=131, iter=246960 - allready processed\n",
      "i=132, iter=247104 - allready processed\n",
      "i=133, iter=247248 - allready processed\n",
      "i=134, iter=247392 - allready processed\n",
      "i=135, iter=247536 - allready processed\n",
      "i=136, iter=247680 - allready processed\n",
      "i=137, iter=247824 - allready processed\n",
      "i=138, iter=247968 - allready processed\n",
      "i=139, iter=248112 - allready processed\n",
      "i=140, iter=248256 - allready processed\n",
      "i=141, iter=248400 - allready processed\n",
      "i=142, iter=248544 - allready processed\n",
      "i=143, iter=248688 - allready processed\n",
      "i=144, iter=248832 - allready processed\n",
      "i=145, iter=248976 - allready processed\n",
      "i=146, iter=249120 - allready processed\n",
      "i=147, iter=249264 - allready processed\n",
      "i=148, iter=249408 - allready processed\n",
      "i=149, iter=249552 - allready processed\n",
      "i=150, iter=249696 - allready processed\n",
      "i=151, iter=249840 - allready processed\n",
      "i=152, iter=249984 - allready processed\n",
      "i=153, iter=250128 - allready processed\n",
      "i=154, iter=250272 - allready processed\n",
      "i=155, iter=250416 - allready processed\n",
      "i=156, iter=250560 - allready processed\n",
      "i=157, iter=250704 - allready processed\n",
      "i=158, iter=250848 - allready processed\n",
      "i=159, iter=250992 - allready processed\n",
      "i=160, iter=251136 - allready processed\n",
      "i=161, iter=251280 - allready processed\n",
      "i=162, iter=251424 - allready processed\n",
      "i=163, iter=251568 - allready processed\n",
      "i=164, iter=251712 - allready processed\n",
      "i=165, iter=251856 - allready processed\n",
      "i=166, iter=252000 - allready processed\n",
      "i=167, iter=252144 - allready processed\n",
      "i=168, iter=252288 - allready processed\n",
      "i=169, iter=252432 - allready processed\n",
      "i=170, iter=252576 - allready processed\n",
      "i=171, iter=252720 - allready processed\n",
      "i=172, iter=252864 - allready processed\n",
      "i=173, iter=253008 - allready processed\n",
      "i=174, iter=253152 - allready processed\n",
      "i=175, iter=253296 - allready processed\n",
      "i=176, iter=253440 - allready processed\n",
      "i=177, iter=253584 - allready processed\n",
      "i=178, iter=253728 - allready processed\n",
      "i=179, iter=253872 - allready processed\n",
      "i=180, iter=254016 - allready processed\n",
      "i=181, iter=254160 - allready processed\n",
      "i=182, iter=254304 - allready processed\n",
      "i=183, iter=254448 - allready processed\n",
      "i=184, iter=254592 - allready processed\n",
      "i=185, iter=254736 - allready processed\n",
      "i=186, iter=254880 - allready processed\n",
      "i=187, iter=255024 - allready processed\n",
      "i=188, iter=255168 - allready processed\n",
      "i=189, iter=255312 - allready processed\n",
      "i=190, iter=255456 - allready processed\n",
      "i=191, iter=255600 - allready processed\n",
      "i=192, iter=255744 - allready processed\n",
      "i=193, iter=255888 - allready processed\n",
      "i=194, iter=256032 - allready processed\n",
      "i=195, iter=256176 - allready processed\n",
      "i=196, iter=256320 - allready processed\n",
      "i=197, iter=256464 - allready processed\n",
      "i=198, iter=256608 - allready processed\n",
      "i=199, iter=256752 - allready processed\n",
      "i=200, iter=256896 - allready processed\n",
      "i=201, iter=257040 - allready processed\n",
      "i=202, iter=257184 - allready processed\n",
      "i=203, iter=257328 - allready processed\n",
      "i=204, iter=257472 - allready processed\n",
      "i=205, iter=257616 - allready processed\n",
      "i=206, iter=257760 - allready processed\n",
      "i=207, iter=257904 - allready processed\n",
      "i=208, iter=258048 - allready processed\n",
      "i=209, iter=258192 - allready processed\n",
      "i=210, iter=258336 - allready processed\n",
      "i=211, iter=258480 - allready processed\n",
      "i=212, iter=258624 - allready processed\n",
      "i=213, iter=258768 - allready processed\n",
      "i=214, iter=258912 - allready processed\n",
      "i=215, iter=259056 - allready processed\n",
      "i=216, iter=259200 - allready processed\n",
      "i=217, iter=259344 - allready processed\n",
      "i=218, iter=259488 - allready processed\n",
      "i=219, iter=259632 - allready processed\n",
      "i=220, iter=259776 - allready processed\n",
      "i=221, iter=259920 - allready processed\n",
      "i=222, iter=260064 - allready processed\n",
      "i=223, iter=260208 - allready processed\n",
      "i=224, iter=260352 - allready processed\n",
      "i=225, iter=260496 - allready processed\n",
      "i=226, iter=260640 - allready processed\n",
      "i=227, iter=260784 - allready processed\n",
      "i=228, iter=260928 - allready processed\n",
      "i=229, iter=261072 - allready processed\n",
      "i=230, iter=261216 - allready processed\n",
      "i=231, iter=261360 - allready processed\n",
      "i=232, iter=261504 - allready processed\n",
      "i=233, iter=261648 - allready processed\n",
      "i=234, iter=261792 - allready processed\n",
      "i=235, iter=261936 - allready processed\n",
      "i=236, iter=262080 - allready processed\n",
      "i=237, iter=262224 - allready processed\n",
      "i=238, iter=262368 - allready processed\n",
      "i=239, iter=262512 - allready processed\n",
      "i=240, iter=262656 - allready processed\n",
      "i=241, iter=262800 - allready processed\n",
      "i=242, iter=262944 - allready processed\n",
      "i=243, iter=263088 - allready processed\n",
      "i=244, iter=263232 - allready processed\n",
      "i=245, iter=263376 - allready processed\n",
      "i=246, iter=263520 - allready processed\n",
      "i=247, iter=263664 - allready processed\n",
      "i=248, iter=263808 - allready processed\n",
      "i=249, iter=263952 - allready processed\n",
      "i=250, iter=264096 - allready processed\n",
      "i=251, iter=264240 - allready processed\n",
      "i=252, iter=264384 - allready processed\n",
      "i=253, iter=264528 - allready processed\n",
      "i=254, iter=264672 - allready processed\n",
      "i=255, iter=264816 - allready processed\n",
      "i=256, iter=264960 - allready processed\n",
      "i=257, iter=265104 - allready processed\n",
      "i=258, iter=265248 - allready processed\n",
      "i=259, iter=265392 - allready processed\n",
      "i=260, iter=265536 - allready processed\n",
      "i=261, iter=265680 - allready processed\n",
      "i=262, iter=265824 - allready processed\n",
      "i=263, iter=265968 - allready processed\n",
      "i=264, iter=266112 - allready processed\n",
      "i=265, iter=266256 - allready processed\n",
      "i=266, iter=266400 - allready processed\n",
      "i=267, iter=266544 - allready processed\n",
      "i=268, iter=266688 - allready processed\n",
      "i=269, iter=266832 - allready processed\n",
      "i=270, iter=266976 - allready processed\n",
      "i=271, iter=267120 - allready processed\n",
      "i=272, iter=267264 - allready processed\n",
      "i=273, iter=267408 - allready processed\n",
      "i=274, iter=267552 - allready processed\n",
      "i=275, iter=267696 - allready processed\n",
      "i=276, iter=267840 - allready processed\n",
      "i=277, iter=267984 - allready processed\n",
      "i=278, iter=268128 - allready processed\n",
      "i=279, iter=268272 - allready processed\n",
      "i=280, iter=268416 - allready processed\n",
      "i=281, iter=268560 - allready processed\n",
      "i=282, iter=268704 - allready processed\n",
      "i=283, iter=268848 - allready processed\n",
      "i=284, iter=268992 - allready processed\n",
      "i=285, iter=269136 - allready processed\n",
      "i=286, iter=269280 - allready processed\n",
      "i=287, iter=269424 - allready processed\n",
      "i=288, iter=269568 - allready processed\n",
      "i=289, iter=269712 - allready processed\n",
      "i=290, iter=269856 - allready processed\n",
      "i=291, iter=270000 - allready processed\n",
      "i=292, iter=270144 - allready processed\n",
      "i=293, iter=270288 - allready processed\n",
      "i=294, iter=270432 - allready processed\n",
      "i=295, iter=270576 - allready processed\n",
      "i=296, iter=270720 - allready processed\n",
      "i=297, iter=270864 - allready processed\n",
      "i=298, iter=271008 - allready processed\n",
      "i=299, iter=271152 - allready processed\n"
     ]
    }
   ],
   "source": [
    "V = ['Eta', 'SST', 'SSS', 'SSU', 'SSV']\n",
    "V = ['SSV']\n",
    "\n",
    "Nt = 1\n",
    "#out_dir = datawork+'/mit_nc/'\n",
    "out_dir = scratch+'/mit_nc_t/'    \n",
    "fsize_bound = 13*60*1e6\n",
    "\n",
    "for v in V:\n",
    "    #\n",
    "    data_dir = root_data_dir+v+'/'\n",
    "    iters, time = get_iters_time(v, data_dir, delta_t=25.)\n",
    "    #\n",
    "    #it = np.arange(time.size/Nt-1).astype(int)*Nt\n",
    "    it = np.arange(300).astype(int)*Nt # tmp\n",
    "    assert it[-1]+Nt<time.size\n",
    "    #\n",
    "    p = 'C'\n",
    "    if v is 'SSU':\n",
    "        p = 'W'\n",
    "    elif v is 'SSV':\n",
    "        p = 'S'\n",
    "    #\n",
    "    ds = get_compressed_data(v, data_dir, grid_dir, iters=iters, time=time, client=client, point=p)\n",
    "    #ds = ds.chunk({'face': 1})\n",
    "    #\n",
    "    for i, t in enumerate(it):\n",
    "        #\n",
    "        file_out = out_dir+'/%s_t%04d.nc'%(v,i)\n",
    "        if not os.path.isfile(file_out) or os.path.getsize(file_out) < fsize_bound:            \n",
    "            dv = ds[v].isel(time=slice(t,t+Nt)) \n",
    "            # should store grid data independantly in a single file\n",
    "            dv = dv.drop(['XC','YC','Depth','rA']).to_dataset()\n",
    "            #\n",
    "            #print(dv)\n",
    "            #\n",
    "            while True:\n",
    "                try:\n",
    "                    #print(dv)\n",
    "                    %time dv.to_netcdf(file_out, mode='w')                    \n",
    "                except:\n",
    "                    print('Failure')\n",
    "                if os.path.isfile(file_out) and os.path.getsize(file_out) > fsize_bound:\n",
    "                    #\n",
    "                    print('i=%d, iter=%d'%(i, iters[i].values))\n",
    "                    break\n",
    "        else:\n",
    "            print('i=%d, iter=%d - allready processed'%(i, iters[i].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.148.0.76:8786\n",
       "  <li><b>Dashboard: </b><a href='http://10.148.0.76:8787/status' target='_blank'>http://10.148.0.76:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>20</li>\n",
       "  <li><b>Cores: </b>280</li>\n",
       "  <li><b>Memory: </b>2000.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.148.0.76:8786' processes=0 cores=0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "```\n",
    "aponte/mit_tmp% ncdump -sh Eta_f01_4.nc\n",
    "\n",
    "netcdf Eta_f01_4 {\n",
    "dimensions:\n",
    "\ttime = UNLIMITED ; // (24 currently)\n",
    "\ti = 4320 ;\n",
    "\tj = 4320 ;\n",
    "variables:\n",
    "\tint64 i(i) ;\n",
    "\t\ti:standard_name = \"x_grid_index\" ;\n",
    "\t\ti:axis = \"X\" ;\n",
    "\t\ti:long_name = \"x-dimension of the t grid\" ;\n",
    "\t\ti:swap_dim = \"XC\" ;\n",
    "\t\ti:_Storage = \"contiguous\" ;\n",
    "\t\ti:_Endianness = \"little\" ;\n",
    "\tint64 j(j) ;\n",
    "\t\tj:standard_name = \"y_grid_index\" ;\n",
    "\t\tj:axis = \"Y\" ;\n",
    "\t\tj:long_name = \"y-dimension of the t grid\" ;\n",
    "\t\tj:swap_dim = \"YC\" ;\n",
    "\t\tj:_Storage = \"contiguous\" ;\n",
    "\t\tj:_Endianness = \"little\" ;\n",
    "\tint64 face ;\n",
    "\t\tface:standard_name = \"face_index\" ;\n",
    "\t\tface:_Endianness = \"little\" ;\n",
    "\tdouble time(time) ;\n",
    "\t\ttime:_FillValue = NaN ;\n",
    "\t\ttime:_Storage = \"chunked\" ;\n",
    "\t\ttime:_ChunkSizes = 512 ;\n",
    "\tfloat Eta(i, j, time) ;\n",
    "\t\tEta:_FillValue = NaNf ;\n",
    "\t\tEta:coordinates = \"face\" ;\n",
    "\t\tEta:_Storage = \"chunked\" ;\n",
    "\t\tEta:_ChunkSizes = 432, 432, 24 ;\n",
    "\n",
    "// global attributes:\n",
    "\t\t:_NCProperties = \"version=1|netcdflibversion=4.6.1|hdf5libversion=1.10.1\" ;\n",
    "\t\t:_Format = \"netCDF-4\" ;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
