Warning: no access to tty (Bad file descriptor).
Thus no job control in this shell.
/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/utils.py:128: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  % (host, default, e), RuntimeWarning)
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.0.202:53214'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.0.202:50096'
/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/utils.py:128: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  % (host, default, e), RuntimeWarning)
distributed.worker - INFO -       Start worker at:   tcp://10.148.0.202:34371
distributed.worker - INFO -          Listening to:   tcp://10.148.0.202:34371
distributed.worker - INFO -              nanny at:         10.148.0.202:50096
distributed.worker - INFO -              bokeh at:          10.148.0.202:8789
distributed.worker - INFO - Waiting to connect to:     tcp://10.148.1.2:35178
distributed.worker - INFO - -------------------------------------------------
/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/utils.py:128: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  % (host, default, e), RuntimeWarning)
distributed.worker - INFO -       Start worker at:   tcp://10.148.0.202:47174
distributed.worker - INFO -          Listening to:   tcp://10.148.0.202:47174
distributed.worker - INFO -              nanny at:         10.148.0.202:53214
distributed.worker - INFO -              bokeh at:         10.148.0.202:36112
distributed.worker - INFO - Waiting to connect to:     tcp://10.148.1.2:35178
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   50.00 GB
distributed.worker - INFO -       Local Directory: /dev/shm/pbs.1346232.datarmor0/worker-2i9ravf5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   50.00 GB
distributed.worker - INFO -       Local Directory: /dev/shm/pbs.1346232.datarmor0/worker-y12loz_n
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:     tcp://10.148.1.2:35178
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://10.148.1.2:35178
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 25.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 12.61 MB from 65084 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/array/chunk.py:228: ComplexWarning: Casting complex values to real discards the imaginary part
  return x.astype(astype_dtype, **kwargs)
distributed.utils_perf - INFO - full garbage collection released 211.94 MB from 733 reference cycles (threshold: 10.00 MB)
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.0.144:60204
Traceback (most recent call last):
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/comm/core.py", line 186, in connect
    quiet_exceptions=EnvironmentError)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1099, in run
    value = future.result()
tornado.util.TimeoutError: Timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/worker.py", line 1774, in gather_dep
    who=self.address)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1099, in run
    value = future.result()
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1107, in run
    yielded = self.gen.throw(*exc_info)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/core.py", line 608, in send_recv_from_rpc
    comm = yield self.pool.connect(self.addr)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1099, in run
    value = future.result()
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1107, in run
    yielded = self.gen.throw(*exc_info)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/core.py", line 719, in connect
    connection_args=self.connection_args)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1099, in run
    value = future.result()
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1107, in run
    yielded = self.gen.throw(*exc_info)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/comm/core.py", line 195, in connect
    _raise(error)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/comm/core.py", line 178, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://10.148.0.144:60204' after 10 s: in <distributed.comm.tcp.TCPConnector object at 0x2aab63b0f5f8>: ConnectionRefusedError: [Errno 111] Connection refused
/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/array/chunk.py:228: ComplexWarning: Casting complex values to real discards the imaginary part
  return x.astype(astype_dtype, **kwargs)
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.0.144:60204
Traceback (most recent call last):
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/comm/core.py", line 186, in connect
    quiet_exceptions=EnvironmentError)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1099, in run
    value = future.result()
tornado.util.TimeoutError: Timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/worker.py", line 1774, in gather_dep
    who=self.address)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1099, in run
    value = future.result()
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1107, in run
    yielded = self.gen.throw(*exc_info)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/core.py", line 608, in send_recv_from_rpc
    comm = yield self.pool.connect(self.addr)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1099, in run
    value = future.result()
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1107, in run
    yielded = self.gen.throw(*exc_info)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/core.py", line 719, in connect
    connection_args=self.connection_args)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1099, in run
    value = future.result()
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py", line 1107, in run
    yielded = self.gen.throw(*exc_info)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/comm/core.py", line 195, in connect
    _raise(error)
  File "/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/comm/core.py", line 178, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://10.148.0.144:60204' after 10 s: in <distributed.comm.tcp.TCPConnector object at 0x2aaafff73710>: ConnectionRefusedError: [Errno 111] Connection refused
distributed.worker - INFO - Can't find dependencies for key ('detrend-multiply-fftn-ff47af91f0a9399d975c9d8173d97c8c', 153, 5, 0)
distributed.worker - INFO - Dependent not found: ('where-df72cf21e168d64356411fd221dff700', 153, 5, 0) 0 .  Asking scheduler
distributed.worker - INFO - Can't find dependencies for key ('detrend-multiply-fftn-ff47af91f0a9399d975c9d8173d97c8c', 153, 5, 0)
distributed.worker - INFO - Dependent not found: ('where-df72cf21e168d64356411fd221dff700', 153, 5, 0) 1 .  Asking scheduler
distributed.utils_perf - INFO - full garbage collection released 11.22 MB from 65745 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 22.54 MB from 130186 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 22.39 MB from 129703 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 29.62 MB from 259404 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 51.60 MB from 0 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 11.01 MB from 64879 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 43.25 MB from 0 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 21.28 MB from 259800 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 20.98 MB from 129852 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 10.90 MB from 64894 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 57.10 MB from 324691 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 11.10 MB from 65148 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO - Stopping worker at tcp://10.148.0.202:47174
distributed.worker - INFO - Stopping worker at tcp://10.148.0.202:34371
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.0.202:53214'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.0.202:50096'
distributed.dask_worker - INFO - End worker
/home1/datahome/xyu/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/utils.py:128: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  % (host, default, e), RuntimeWarning)
