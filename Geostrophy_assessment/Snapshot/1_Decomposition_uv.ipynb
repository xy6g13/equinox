{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import dask\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mitequinox.utils import *\n",
    "from mitequinox.sigp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import PBSCluster\n",
    "# for heavy processing:\n",
    "#cluster = PBSCluster(cores=6, processes=6, walltime='06:00:00')\n",
    "#w = cluster.scale(6*10)\n",
    "\n",
    "cluster = PBSCluster(cores=6, processes=6,  walltime='06:00:00')\n",
    "w = cluster.scale(12*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dask handles and check dask server status\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.135.39.27:41390</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.135.39.27:8787/status' target='_blank'>http://10.135.39.27:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>120</li>\n",
       "  <li><b>Cores: </b>120</li>\n",
       "  <li><b>Memory: </b>2.00 TB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.135.39.27:41390' processes=120 threads=120, memory=2.00 TB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "# Calculating total-uv, ageo-uv and geo-uv\n",
    "\n",
    "## Notes on 2020.03.24; added on 2020.09.20\n",
    "### 1. Total-uv is the modelled uv.\n",
    "### 2. Geo-uv is the one estimated from geostrophic balance (in terms of Eta gradients and Coriolis force).\n",
    "### 3. Ageo-uv is the difference between modelled uv and geo uv.\n",
    "### 4. These results (u,u_g,u_a; v,v_g,v_a) (1080*1080*13) are stored at /work/ALT/swot/aval/syn/xy/comparison\n",
    "### 5. each face may need 3-5 mins to calculate and store, under cluster = PBSCluster(cores=6, processes=6,  walltime='06:00:00'); w = cluster.scale(12*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (face: 13, i: 4320, j: 4320)\n",
      "Coordinates:\n",
      "  * face     (face) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
      "  * i        (i) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
      "  * j        (j) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
      "Data variables:\n",
      "    mask     (face, j, i) bool dask.array<chunksize=(1, 4320, 4320), meta=np.ndarray>\n",
      "    XC       (face, j, i) float32 dask.array<chunksize=(1, 4320, 4320), meta=np.ndarray>\n",
      "    YC       (face, j, i) float32 dask.array<chunksize=(1, 4320, 4320), meta=np.ndarray>\n",
      "    Depth    (face, j, i) float32 dask.array<chunksize=(1, 4320, 4320), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "#grd = load_grd(ftype='nc').reset_coords()\n",
    "grd = load_grd().reset_coords()\n",
    "mask = ((grd.hFacW.rename({'i_g': 'i'}) == 1) &\n",
    "        (grd.hFacS.rename({'j_g': 'j'}) == 1) \n",
    "       ).rename('mask').reset_coords(drop=True)\n",
    "grd_rspec = xr.merge([mask, grd.XC, grd.YC, grd.Depth])\n",
    "print(grd_rspec)\n",
    "\n",
    "# !! chunking is coarse for the netcdf grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'YC' (face: 13, j: 4320, i: 4320)>\n",
       "dask.array<mul, shape=(13, 4320, 4320), dtype=float32, chunksize=(1, 4320, 4320), chunktype=numpy.ndarray>\n",
       "Coordinates:\n",
       "  * face     (face) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "  * i        (i) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
       "  * j        (j) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coriolis term\n",
    "lat = grd_rspec['YC']\n",
    "omega = 7.3/100000\n",
    "f_ij = 2*omega*np.sin(np.deg2rad(lat))\n",
    "f_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (i: 1080, j: 1080, time: 8640)\n",
      "Coordinates:\n",
      "    dxC      (j, i) float32 dask.array<chunksize=(24, 47), meta=np.ndarray>\n",
      "    dyG      (j, i) float32 dask.array<chunksize=(24, 47), meta=np.ndarray>\n",
      "    f_j      (j, i) float32 dask.array<chunksize=(24, 47), meta=np.ndarray>\n",
      "    face     int64 1\n",
      "  * i        (i) int64 0 4 8 12 16 20 24 ... 4292 4296 4300 4304 4308 4312 4316\n",
      "  * j        (j) int64 0 4 8 12 16 20 24 ... 4292 4296 4300 4304 4308 4312 4316\n",
      "  * time     (time) float64 5.702e+06 5.706e+06 5.71e+06 ... 3.68e+07 3.68e+07\n",
      "    dxG      (j, i) float32 dask.array<chunksize=(24, 47), meta=np.ndarray>\n",
      "    dyC      (j, i) float32 dask.array<chunksize=(24, 47), meta=np.ndarray>\n",
      "    f_i      (j, i) float32 dask.array<chunksize=(24, 47), meta=np.ndarray>\n",
      "    Depth    (j, i) float32 dask.array<chunksize=(1080, 1080), meta=np.ndarray>\n",
      "    XC       (j, i) float32 dask.array<chunksize=(1080, 1080), meta=np.ndarray>\n",
      "    YC       (j, i) float32 dask.array<chunksize=(1080, 1080), meta=np.ndarray>\n",
      "    mask     (j, i) bool dask.array<chunksize=(1080, 1080), meta=np.ndarray>\n",
      "Data variables:\n",
      "    u_ageo   (time, j, i) float32 dask.array<chunksize=(8640, 24, 47), meta=np.ndarray>\n",
      "    u_geo    (time, j, i) float32 dask.array<chunksize=(8640, 24, 47), meta=np.ndarray>\n",
      "    u        (j, i, time) float32 dask.array<chunksize=(24, 47, 8640), meta=np.ndarray>\n",
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (i: 1080, j: 1080, time: 8640)\n",
      "Coordinates:\n",
      "    dxC      (j, i) float32 dask.array<chunksize=(188, 192), meta=np.ndarray>\n",
      "    dyG      (j, i) float32 dask.array<chunksize=(188, 192), meta=np.ndarray>\n",
      "    f_j      (j, i) float32 dask.array<chunksize=(188, 192), meta=np.ndarray>\n",
      "    face     int64 1\n",
      "  * i        (i) int64 0 4 8 12 16 20 24 ... 4292 4296 4300 4304 4308 4312 4316\n",
      "  * j        (j) int64 0 4 8 12 16 20 24 ... 4292 4296 4300 4304 4308 4312 4316\n",
      "  * time     (time) float64 5.702e+06 5.706e+06 5.71e+06 ... 3.68e+07 3.68e+07\n",
      "    dxG      (j, i) float32 dask.array<chunksize=(188, 192), meta=np.ndarray>\n",
      "    dyC      (j, i) float32 dask.array<chunksize=(188, 192), meta=np.ndarray>\n",
      "    f_i      (j, i) float32 dask.array<chunksize=(188, 192), meta=np.ndarray>\n",
      "    Depth    (j, i) float32 dask.array<chunksize=(188, 192), meta=np.ndarray>\n",
      "    XC       (j, i) float32 dask.array<chunksize=(188, 192), meta=np.ndarray>\n",
      "    YC       (j, i) float32 dask.array<chunksize=(188, 192), meta=np.ndarray>\n",
      "    mask     (j, i) bool dask.array<chunksize=(188, 192), meta=np.ndarray>\n",
      "Data variables:\n",
      "    u_ageo   (time, j, i) float32 dask.array<chunksize=(8640, 188, 192), meta=np.ndarray>\n",
      "    u_geo    (time, j, i) float32 dask.array<chunksize=(8640, 188, 192), meta=np.ndarray>\n",
      "    u        (j, i, time) float32 dask.array<chunksize=(188, 192, 8640), meta=np.ndarray>\n",
      "CPU times: user 2min 44s, sys: 7.85 s, total: 2min 52s\n",
      "Wall time: 3min 28s\n",
      "--- face 1 done\n"
     ]
    }
   ],
   "source": [
    "# u, geo_u, ageo_u\n",
    "\n",
    "dij=4\n",
    "overwrite=True\n",
    "    \n",
    "#for face in range(13):\n",
    "for face in [1]:\n",
    "\n",
    "    Efile = work_data_dir+'xy/comparison/u_try_f%02d.zarr'%(face)\n",
    "\n",
    "    if not os.path.isdir(Efile) or overwrite:\n",
    "\n",
    "        # load data\n",
    "        dsu = ( xr.open_zarr(work_data_dir+'rechunked/%s_mbal_xy_f%02d.zarr'%('u',face))\n",
    "                .isel(i_g=slice(0,None,dij), j=slice(0,None,dij)) )\n",
    "        dsv = (xr.open_zarr(work_data_dir+'rechunked/%s_mbal_xy_f%02d.zarr'%('v',face))\n",
    "               .isel(i=slice(0,None,dij), j_g=slice(0,None,dij)) )\n",
    "        fs = f_ij.isel(face=face, i=slice(0,None,dij), j=slice(0,None,dij))\n",
    "        \n",
    "        ds = xr.merge([dsu.rename({'i_g': 'i'}), dsv.rename({'j_g': 'j'})], \n",
    "                      compat='equals').assign_coords(**grd_rspec.sel(face=face))\n",
    "\n",
    "        # !!! check signs (checked on 08/30), will need to be normalized by Coriolis frequency !!!\n",
    "        \n",
    "        # compute ageostrophic velocities\n",
    "        ds['u_ageo'] =  (ds['v_gradp'] -  ds['v_coriolis_linear'])/fs\n",
    "        ds['u_geo'] =  (-ds['v_gradp'])/fs\n",
    "        ds['u'] =  -ds['v_coriolis_linear']/fs\n",
    "        E = xr.merge([ds['u_ageo'],ds['u_geo'],ds['u']])\n",
    "        print(E)\n",
    "        #ds['v_ageo'] =  (-ds['u_gradp'] +  ds['u_coriolis_linear'])/fs \n",
    "        #ds['v_geo'] =  (ds['u_gradp'])/fs\n",
    "        #ds['v'] =  ds['u_coriolis_linear']/fs \n",
    "        #E = xr.merge([ds['v_ageo'],ds['v_geo'],ds['v']])\n",
    "        \n",
    "        # store\n",
    "        for c in E.coords:\n",
    "            try:\n",
    "                del E[c].encoding['chunks']\n",
    "            except:\n",
    "                print(c)\n",
    "\n",
    "        E = E.chunk({'i': 24*8, 'j':47*4})\n",
    "        print(E)\n",
    "        %time E.to_zarr(Efile, mode='w')\n",
    "        print('--- face %d done'%face)\n",
    "\n",
    "    else:\n",
    "        print('--- face %d allready computed'%face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n",
      "CPU times: user 1min 15s, sys: 3.79 s, total: 1min 19s\n",
      "Wall time: 1min 33s\n",
      "--- face 0 done\n",
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n",
      "CPU times: user 1min 55s, sys: 8.03 s, total: 2min 3s\n",
      "Wall time: 4min 59s\n",
      "--- face 1 done\n",
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n",
      "CPU times: user 1min 15s, sys: 6.43 s, total: 1min 22s\n",
      "Wall time: 1min 51s\n",
      "--- face 2 done\n",
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 4.25 s, total: 1min 8s\n",
      "Wall time: 1min 13s\n",
      "--- face 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 54s, sys: 7.43 s, total: 2min 1s\n",
      "Wall time: 3min 2s\n",
      "--- face 4 done\n",
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n",
      "CPU times: user 49.3 s, sys: 2.71 s, total: 52 s\n",
      "Wall time: 55.9 s\n",
      "--- face 5 done\n",
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n",
      "CPU times: user 1min 12s, sys: 4.42 s, total: 1min 17s\n",
      "Wall time: 1min 26s\n",
      "--- face 6 done\n",
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 2s, sys: 7.8 s, total: 2min 10s\n",
      "Wall time: 3min 16s\n",
      "--- face 7 done\n",
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n",
      "CPU times: user 2min 1s, sys: 9.09 s, total: 2min 10s\n",
      "Wall time: 4min 5s\n",
      "--- face 8 done\n",
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n",
      "CPU times: user 2min 5s, sys: 7.49 s, total: 2min 13s\n",
      "Wall time: 2min 49s\n",
      "--- face 9 done\n",
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n",
      "CPU times: user 2min 5s, sys: 9.04 s, total: 2min 14s\n",
      "Wall time: 2min 47s\n",
      "--- face 10 done\n",
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n",
      "CPU times: user 3min 8s, sys: 10.8 s, total: 3min 19s\n",
      "Wall time: 4min 51s\n",
      "--- face 11 done\n",
      "dxC\n",
      "dyG\n",
      "f_j\n",
      "face\n",
      "dxG\n",
      "dyC\n",
      "f_i\n",
      "Depth\n",
      "XC\n",
      "YC\n",
      "mask\n",
      "CPU times: user 2min 13s, sys: 7.84 s, total: 2min 21s\n",
      "Wall time: 3min 25s\n",
      "--- face 12 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz/yux/.conda/envs/equinox/lib/python3.7/site-packages/distributed/scheduler.py:313: UserWarning: WorkerState.ncores has moved to WorkerState.nthreads\n",
      "  warnings.warn(\"WorkerState.ncores has moved to WorkerState.nthreads\")\n"
     ]
    }
   ],
   "source": [
    "# v, geo_v, ageo_v\n",
    "\n",
    "dij=4\n",
    "overwrite=True\n",
    "    \n",
    "for face in range(13):\n",
    "#for face in [1]:\n",
    "\n",
    "    Efile = work_data_dir+'xy/comparison/v_f%02d.zarr'%(face)\n",
    "\n",
    "    if not os.path.isdir(Efile) or overwrite:\n",
    "\n",
    "        # load data\n",
    "        dsu = ( xr.open_zarr(work_data_dir+'rechunked/%s_mbal_xy_f%02d.zarr'%('u',face))\n",
    "                .isel(i_g=slice(0,None,dij), j=slice(0,None,dij)) )\n",
    "        dsv = (xr.open_zarr(work_data_dir+'rechunked/%s_mbal_xy_f%02d.zarr'%('v',face))\n",
    "               .isel(i=slice(0,None,dij), j_g=slice(0,None,dij)) )\n",
    "        fs = f_ij.isel(face=face, i=slice(0,None,dij), j=slice(0,None,dij))\n",
    "        \n",
    "        ds = xr.merge([dsu.rename({'i_g': 'i'}), dsv.rename({'j_g': 'j'})], \n",
    "                      compat='equals').assign_coords(**grd_rspec.sel(face=face))\n",
    "\n",
    "        # !!! check signs (checked on 08/30), will need to be normalized by Coriolis frequency !!!\n",
    "\n",
    "        ds['v_ageo'] =  (-ds['u_gradp'] +  ds['u_coriolis_linear'])/fs\n",
    "        ds['v_geo'] =  (ds['u_gradp'])/fs\n",
    "        ds['v'] =  ds['u_coriolis_linear']/fs \n",
    "        E = xr.merge([ds['v_ageo'],ds['v_geo'],ds['v']])\n",
    "\n",
    "        #ds['u_ageo'] =  (ds['v_gradp'] -  ds['v_coriolis_linear'])/fs\n",
    "        #ds['u_geo'] =  (-ds['v_gradp'])/fs\n",
    "        #ds['u'] =  -ds['v_coriolis_linear']/fs        \n",
    "        #E = xr.merge([ds['u_ageo'],ds['u_geo'],ds['u']])\n",
    "\n",
    "        # store\n",
    "        for c in E.coords:\n",
    "            try:\n",
    "                del E[c].encoding['chunks']\n",
    "            except:\n",
    "                print(c)        \n",
    "        E = E.chunk({'i': 24*8, 'j':47*4})\n",
    "        %time E.to_zarr(Efile, mode='w')\n",
    "\n",
    "        print('--- face %d done'%face)\n",
    "\n",
    "    else:\n",
    "        print('--- face %d allready computed'%face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "CPU times: user 10.8 s, sys: 803 ms, total: 11.6 s\n",
      "Wall time: 15.2 s\n",
      "--- face 1 done\n"
     ]
    }
   ],
   "source": [
    "# Eta\n",
    "time_length = 8640\n",
    "dij=4\n",
    "overwrite=True\n",
    "    \n",
    "#for face in range(13):\n",
    "for face in [1]:\n",
    "\n",
    "    Efile = work_data_dir+'xy/SSH/Eta_f%02d.zarr'%(face)\n",
    "\n",
    "    if not os.path.isdir(Efile) or overwrite:\n",
    "\n",
    "        # load data\n",
    "        dsE = xr.open_zarr(root_data_dir+'zarr/%s.zarr'%('Eta')).isel(time=slice(1512,1512+time_length),face=face, i=slice(0,None,dij), j=slice(0,None,dij))\n",
    "        \n",
    "        del dsE['Eta'].encoding['chunks']\n",
    "        del dsE['time'].encoding['chunks']\n",
    "        #dsE = dsE.chunk({'time':time_length, 'i': 24*8, 'j':47*4})    \n",
    "        \n",
    "        # store\n",
    "        for c in dsE.coords:\n",
    "            try:\n",
    "                del dsE[c].encoding['chunks']\n",
    "            except:\n",
    "                print(c)\n",
    "\n",
    "        dsE = dsE.chunk({'time':time_length, 'i': 24*8, 'j':47*4}) \n",
    "        %time dsE.to_zarr(Efile, mode='w')\n",
    "        print('--- face %d done'%face)\n",
    "\n",
    "    else:\n",
    "        print('--- face %d allready computed'%face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (i: 1080, j: 1080, time: 8640)\n",
       "Coordinates:\n",
       "    dtime    (time) datetime64[ns] dask.array<chunksize=(8640,), meta=np.ndarray>\n",
       "    face     int64 ...\n",
       "  * i        (i) int64 0 4 8 12 16 20 24 ... 4292 4296 4300 4304 4308 4312 4316\n",
       "    iters    (time) int64 dask.array<chunksize=(8640,), meta=np.ndarray>\n",
       "  * j        (j) int64 0 4 8 12 16 20 24 ... 4292 4296 4300 4304 4308 4312 4316\n",
       "  * time     (time) float64 5.702e+06 5.706e+06 5.71e+06 ... 3.68e+07 3.68e+07\n",
       "Data variables:\n",
       "    Eta      (time, j, i) float32 dask.array<chunksize=(8640, 188, 192), meta=np.ndarray>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =  xr.open_zarr(work_data_dir+'xy/SSH/Eta_f%02d.zarr'%(face))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "distributed.utils - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uz/yux/.conda/envs/equinox/lib/python3.7/site-packages/distributed/utils.py\", line 666, in log_errors\n",
      "    yield\n",
      "  File \"/home/uz/yux/.conda/envs/equinox/lib/python3.7/site-packages/distributed/client.py\", line 1276, in _close\n",
      "    await gen.with_timeout(timedelta(seconds=2), list(coroutines))\n",
      "concurrent.futures._base.CancelledError\n",
      "distributed.utils - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uz/yux/.conda/envs/equinox/lib/python3.7/site-packages/distributed/utils.py\", line 666, in log_errors\n",
      "    yield\n",
      "  File \"/home/uz/yux/.conda/envs/equinox/lib/python3.7/site-packages/distributed/client.py\", line 1005, in _reconnect\n",
      "    await self._close()\n",
      "  File \"/home/uz/yux/.conda/envs/equinox/lib/python3.7/site-packages/distributed/client.py\", line 1276, in _close\n",
      "    await gen.with_timeout(timedelta(seconds=2), list(coroutines))\n",
      "concurrent.futures._base.CancelledError\n"
     ]
    }
   ],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equinox",
   "language": "python",
   "name": "equinox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
